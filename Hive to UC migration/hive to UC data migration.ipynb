{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f065f73c-f1ab-4cee-bdea-2504e41aaa02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_catalog = \"newdbhive\"\n",
    "\n",
    "# Step 1: Get all Hive schemas\n",
    "hive_schemas = [row.databaseName for row in spark.sql(\"SHOW DATABASES IN hive_metastore\").collect()]\n",
    "\n",
    "system_schemas = {\"default\", \"information_schema\"}\n",
    "\n",
    "for hive_schema in hive_schemas:\n",
    "    if hive_schema in system_schemas:\n",
    "        continue\n",
    "\n",
    "    target_schema = \"{}.{}\".format(target_catalog, hive_schema)\n",
    "    print(\"\\n=== Processing schema: {} → {} ===\".format(hive_schema, target_schema))\n",
    "\n",
    "    # Step 2: Create schema in UC if not exists\n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS {}\".format(target_schema))\n",
    "\n",
    "    # Step 3: Fetch UC table list once per schema (fix for duplicate creation)\n",
    "    uc_existing_tables = [r.tableName for r in spark.sql(\"SHOW TABLES IN {}\".format(target_schema)).collect()]\n",
    "\n",
    "    # Step 4: List Hive tables\n",
    "    hive_tables = [row.tableName for row in spark.sql(\n",
    "        \"SHOW TABLES IN hive_metastore.{}\".format(hive_schema)\n",
    "    ).collect()]\n",
    "\n",
    "    for table in hive_tables:\n",
    "        src = \"hive_metastore.{}.{}\".format(hive_schema, table)\n",
    "        dest = \"{}.{}\".format(target_schema, table)\n",
    "\n",
    "        print(\"→ Checking table: {} → {}\".format(src, dest))\n",
    "\n",
    "        if table not in uc_existing_tables:\n",
    "            print(\"   Creating new UC table {}\".format(dest))\n",
    "            spark.sql(\"CREATE TABLE {} AS SELECT * FROM {}\".format(dest, src))\n",
    "            # Add to existing table list to prevent re-creation in same run\n",
    "            uc_existing_tables.append(table)\n",
    "        else:\n",
    "            print(\"   UC table {} already exists — appending data\".format(dest))\n",
    "            src_df = spark.table(src)\n",
    "            src_df.write.mode(\"append\").saveAsTable(dest)\n",
    "\n",
    "print(\"\\n✅ Migration completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "hive to UC data migration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
